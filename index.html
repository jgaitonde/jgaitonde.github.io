
<!DOCTYPE html>
<html>
<title>Jason Gaitonde</title>

<head>
<style type="text/css">
    a{ text-decoration:none; }
    a:visited{color:#0080ff;}
    a:link{color:#0000ff;}
    a:hover{text-decoration:underline;}
    p.ex { height:auto; }
    .alignleft { float: left; }
    .alignright { float: right; }
    hr { width:800px; }
    body{
	line-height: 1.5;
	padding: 4em 1em;
	width:800px;
	margin-left:auto;
	margin-right:auto;
	font-size:1.03em;
	font-family: "Helvetica", "Arial", sans-serif;
    }
    author { font-style: italic; }
    conference { font-weight: bold; }
    ptitle {
	color: #0A2162;
	font-weight: bolder;
    }
</style>

<script type="text/javascript" src="https://code.jquery.com/jquery-1.9.1.js"> </script>
   <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
   <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]}
      });
   </script>
</head>

<body>
<h1 style="margin-bottom:2mm;">Jason Gaitonde</h1>
<hr>

<p style = "margin-top:1mm">
<i> Email: gaitonde AT mit DOT edu </i>
</p>

<p class="text-justify">
I am a Postdoctoral Associate in the <a href="https://math.mit.edu/">Department of Mathematics</a> at MIT, where I work with <A HREF="https://math.mit.edu/~elmos/"   target="_blank">Elchanan Mossel</A>. Previously, I received my PhD from the <a href="https://www.cs.cornell.edu/">Department of Computer Science</a> at Cornell University, where I was very fortunate to be advised by <A HREF="http://www.cs.cornell.edu/~eva/"   target="_blank">&Eacuteva Tardos</A>. Even before that, I graduated from Yale University with degrees in <A HREF = "https://math.yale.edu/" >Mathematics </A>(B.S., with distinction) and <A HREF = "https://economics.yale.edu/"> Economics </A>(B.A.).
</p>

<p class="text-justify">
        I am broadly interested in theoretical computer science. In particular, my research focuses on theoretical problems at the intersection of algorithms, learning, game theory, networks, and randomness.
    </p>
<hr>

<font size="6" >Papers</font><OL>

  <font size="4" color="#606060">Preprints</font>

  <LI><b>Efficiently Learning Markov Random Fields from Dynamics,</b> with Ankur Moitra and Elchanan Mossel. <br> <i>Preprint.</i> <br>[<a onclick='$("#abstract_div_gmm24").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/abs/2409.05284' target='_blank'>PDF</a>]<br><div id='abstract_div_gmm24' style='display:none'><hr>An important task in high-dimensional statistics is learning the parameters or dependency structure of an undirected graphical model, or Markov random field (MRF). Much of the prior work on this problem assumes access to i.i.d. samples from the MRF distribution and state-of-the-art algorithms succeed using $n^{\Theta(k)}$ runtime, where $n$ is the dimension and $k$ is the order of the interactions. However, well-known reductions from the sparse parity with noise problem imply that given i.i.d. samples from a sparse, order-$k$ MRF, any learning algorithm likely requires $n^{\Omega(k)}$ time, impeding the potential for significant computational improvements. In this work, we demonstrate that these fundamental barriers for learning MRFs can surprisingly be completely circumvented when learning from natural, dynamical samples. We show that in bounded-degree MRFs, the dependency structure and parameters can be recovered using a trajectory of Glauber dynamics of length $O(n\log n)$ with runtime $O(n^2\log n)$. The implicit constants depend only on the degree and non-degeneracy parameters of the model, but not the dimension $n$. In particular, learning MRFs from dynamics is provably computationally easier than learning from i.i.d. samples under standard hardness assumptions.         <hr></div></LI>


<LI><b>Sample-Efficient Linear Regression with Self-Selection Bias,</b> with Elchanan Mossel. <br> <i>In submission.</i> <br>[<a onclick='$("#abstract_div_gm24").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/abs/2402.14229' target='_blank'>PDF</a>]<br><div id='abstract_div_gm24' style='display:none'><hr>We consider the problem of linear regression with self-selection bias in the unknown-index setting, as introduced in recent work by Cherapanamjeri, Daskalakis, Ilyas, and Zampetakis [STOC 2023]. In this model, one observes m i.i.d. samples $(\mathbf{x}_{\ell},z_{\ell})_{\ell=1}^m$ where $z_{\ell}=\max_{i\in [k]}\{\mathbf{x}_{\ell}^T\mathbf{w}_i+\eta_{\ell,i}\}$, but the maximizing index $i_{\ell}$ is unobserved. Here, the $\mathbf{x}_{\ell}$ are assumed to be $\mathcal{N}(0,I_n)$ and the noise distribution $\mathbf{\eta}\sim \mathcal{D}$ is centered and independent of $\mathbf{x}_{\ell}$. We provide a novel and near optimally sample-efficient (in terms of $k$) algorithm to recover $\mathbf{w}_1,\ldots,\mathbf{w}_k\in \mathbb{R}^n$ up to additive $\ell_2$-error $\varepsilon$ with polynomial sample complexity $\tilde{O}(n)\cdot \mathsf{poly}(k,1/\varepsilon)$ and significantly improved time complexity $\mathsf{poly}(n,k,1/\varepsilon)+O(\log(k)/\varepsilon)^{O(k)}$. When $k=O(1)$, our algorithm runs in $\mathsf{poly}(n,1/\varepsilon)$ time, generalizing the polynomial guarantee of an explicit moment matching algorithm of Cherapanamjeri, et al. for $k=2$ and when it is known that $\mathcal{D}=\mathcal{N}(0,I_k)$. Our algorithm succeeds under significantly relaxed noise assumptions, and therefore also succeeds in the related setting of max-linear regression where the added noise is taken outside the maximum. For this problem, our algorithm is efficient in a much larger range of $k$ than the state-of-the-art due to Ghosh, Pananjady, Guntuboyina, and Ramchandran [IEEE Trans. Inf. Theory 2022] for not too small $\varepsilon$, and leads to improved algorithms for any $\varepsilon$ by providing a warm start for existing local convergence methods.         <hr></div></LI>

<br>

<font size="4" color="#606060">Journal Papers</font>
<LI><b>Bounds on the Covariance Matrix of the Sherrington-Kirkpatrick Model,</b> with Ahmed El Alaoui. <br> <i>Electronic Communications in Probability 2024.</i> <br>[<a onclick='$("#abstract_div_eag22").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://projecteuclid.org/journals/electronic-communications-in-probability/volume-29/issue-none/Bounds-on-the-covariance-matrix-of-the-SherringtonKirkpatrick-model/10.1214/24-ECP582.full' target='_blank'>PDF</a>]<br><div id='abstract_div_eag22' style='display:none'><hr>We consider the Sherrington-Kirkpatrick model with no external field and inverse temperature $\beta<1$ and prove that the expected operator norm of the covariance matrix of the Gibbs measure is bounded by a constant depending only on $\beta$.
This answers an open question raised by Talagrand, who proved a bound of $C(\beta) (\log n)^8$.
Our result follows by establishing an approximate formula for the covariance matrix which we obtain by differentiating the TAP equations and then optimally controlling the associated error terms. We complement this result by showing diverging lower bounds on the operator norm, both at the critical and low temperatures.     <hr></div></LI>


<LI><b>The Price of Anarchy of Strategic Queuing Systems,</b> with &Eacuteva Tardos.<br> <i>Journal of the ACM 2023 (JACM 2023)</i><br>[<a onclick='$("#abstract_div_gt23").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://dl.acm.org/doi/10.1145/3587250' target='_blank'>PDF</a>]<br><div id='abstract_div_gt23' style='display:none'><hr>Bounding the price of anarchy, which quantifies the damage to social welfare due to selfish behavior of the participants, has been an important area of research in algorithmic game theory. Classical work on such bounds in repeated games makes the strong assumption that the subsequent rounds of the repeated games are independent beyond any influence on play from past history. This work studies such bounds in environments that themselves change due to the actions of the agents. Concretely, we consider this problem in discrete-time queuing systems, where competitive queues try to get their packets served. In this model, a queue gets to send a packet at each step to one of the servers, which will attempt to serve the oldest arriving packet, and unprocessed packets are returned to each queue. We model this as a repeated game where queues compete for the capacity of the servers, but where the state of the game evolves as the length of each queue varies.
We analyze this queuing system from multiple perspectives. As a baseline measure, we first establish precise conditions on the queuing arrival rates and service capacities that ensure all packets clear efficiently under centralized coordination. We then show that if queues strategically choose servers according to independent and stationary distributions, the system remains stable provided it would be stable under coordination with arrival rates scaled up by a factor of just $e/(e-1)$. Finally, we extend these results to no-regret learning dynamics: if queues use learning algorithms satisfying the no-regret property to choose servers, then the requisite factor increases to 2, and both of these bounds are tight. Both of these results require new probabilistic techniques compared to the classical price of anarchy literature and show that in such settings, no-regret learning can exhibit efficiency loss due to myopia. <hr></div></LI>

<br>
  <font size="4" color="#606060">Conference Papers</font>

  <LI><b>A Unified Approach to Learning Ising Models: Beyond Independence and Bounded Width,</b> with Elchanan Mossel.<br><i>Symposium on Theory of Computing 2024 (STOC 2024) </i>.<br>[<a onclick='$("#abstract_div_gm23").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/abs/2311.09197' target='_blank'>PDF</a>]<br><div id='abstract_div_gm23' style='display:none'><hr>We revisit the problem of efficiently learning the underlying parameters of Ising models from data. Current algorithmic approaches achieve essentially optimal sample complexity when given i.i.d. samples from the stationary measure and the underlying model satisfies "width" bounds on the total $\ell_1$ interaction involving each node. We show that a simple existing approach based on node-wise logistic regression provably succeeds at recovering the underlying model in several new settings where these assumptions are violated:
    <ol>
  <li>Given dynamically generated data from a wide variety of local Markov chains, like block or round-robin dynamics, logistic regression recovers the parameters with optimal sample complexity up to loglogn factors. This generalizes the specialized algorithm of Bresler, Gamarnik, and Shah [IEEE Trans. Inf. Theory'18] for structure recovery in bounded degree graphs from Glauber dynamics.</li>
  <li>For the Sherrington-Kirkpatrick model of spin glasses, given $\mathsf{poly}(n)$ independent samples, logistic regression recovers the parameters in most of the known high-temperature regime via a simple reduction to weaker structural properties of the measure. This improves on recent work of Anari, Jain, Koehler, Pham, and Vuong [SODA'23] which gives distribution learning at higher temperature.</li>
  <li>As a simple byproduct of our techniques, logistic regression achieves an exponential improvement in learning from samples in the M-regime of data considered by Dutt, Lokhov, Vuffray, and Misra [ICML'21] as well as novel guarantees for learning from the adversarial Glauber dynamics of Chin, Moitra, Mossel, and Sandon [ArXiv'23].</li>
</ol>
Our approach thus significantly generalizes the elegant analysis of Wu, Sanghavi, and Dimakis [Neurips'19] without any algorithmic modification.     <hr></div></LI>

  <LI><b>Budget Pacing in Repeated Auctions: Regret and Efficiency without Convergence,</b> with Yingkai Li, Bar Light, Brendan Lucier, and Aleksandrs Slivkins. <br> <i>Innovations in Theoretical Computer Science 2023 (ITCS 2023)</i>.<br>[<a onclick='$("#abstract_div_gllls23").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/abs/2205.08674' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=TxxWcU1to70' target='_blank'>ITCS Talk</a>]<br><div id='abstract_div_gllls23' style='display:none'><hr>We study the aggregate welfare and individual regret guarantees of dynamic pacing algorithms in the context of repeated auctions with budgets.
    Such algorithms are commonly used as bidding agents in Internet advertising platforms.
    We show that when agents simultaneously apply a natural form of
    gradient-based pacing, the liquid welfare obtained over the course of the learning dynamics is at least half the optimal expected liquid welfare obtainable by any allocation rule.
    Crucially, this result holds without requiring convergence of the dynamics,
    allowing us to circumvent known complexity-theoretic obstacles of finding equilibria.
    This result is also robust to the correlation structure between agent valuations and holds for any core auction, a broad class of auctions that includes first-price, second-price, and generalized second-price auctions.  For individual guarantees, we further show such pacing algorithms enjoy dynamic regret bounds for individual value maximization, with respect to the sequence of budget-pacing bids, for any auction satisfying a monotone bang-for-buck property.  <hr></div></LI>

  <LI><b>Eigenstripping, Spectral Decay, and Edge-Expansion on Posets,</b> with Max Hopkins, Tali Kaufman, Shachar Lovett, and Ruizhe Zhang. <br> <i>International Conference on Randomization and Computation 2022 (RANDOM 2022)</i>.<br>[<a onclick='$("#abstract_div_ghklz22").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/abs/2205.00644' target='_blank'>PDF</a>]<br><div id='abstract_div_ghklz22' style='display:none'><hr>Fast mixing of random walks on hypergraphs (simplicial complexes) has recently led to myriad breakthroughs throughout theoretical computer science. Many important applications, however, (e.g.\ to LTCs, 2-2 games) rely on a more general class of underlying structures called \emph{posets}, and crucially take advantage of non-simplicial structure. These works make it clear that the global expansion properties of posets depend strongly on their underlying architecture (e.g.\ simplicial, cubical, linear algebraic), but the overall phenomenon remains poorly understood. In this work, we quantify the advantage of different poset architectures in both a spectral and combinatorial sense, highlighting how \emph{regularity} controls the spectral decay and edge-expansion of corresponding random walks.

  We show that the spectra of walks on expanding posets (Dikstein, Dinur, Filmus, Harsha APPROX-RANDOM 2018) concentrate in strips around a small number of approximate eigenvalues controlled by the regularity of the underlying poset. This gives a simple condition to identify poset architectures (e.g. the Grassmann) that exhibit strong (even exponential) decay of eigenvalues, versus architectures like hypergraphs whose eigenvalues decay linearly---a crucial distinction in applications to hardness of approximation and agreement testing such as the recent proof of the 2-2 Games Conjecture (Khot, Minzer, Safra FOCS 2018). We show these results lead to a tight characterization of edge-expansion on expanding posets in the $\ell_2$-regime (generalizing recent work of Bafna, Hopkins, Kaufman, and Lovett (SODA 2022)), and pay special attention to the case of the Grassmann where we show our results are tight for a natural set of sparsifications of the Grassmann graphs. We note for clarity that our results do not recover the characterization of expansion used in the proof of the 2-2 Games Conjecture which relies on $\ell_\infty$ rather than $\ell_2$-structure. <hr></div></LI>

  <LI><b>Fractional Pseudorandom Generators from Any Fourier Level,</b> with Eshan Chattopadhyay, Chin Ho Lee, Shachar Lovett, and Abhishek Shetty. <br> <i>Computational Complexity Conference 2021 (CCC 2021)</i>.<br>[<a onclick='$("#abstract_div_cglls20").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/pdf/2008.01316' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=fw7l-x17RLM' target='_blank'>CCC Talk</a>]<br><div id='abstract_div_cglls20' style='display:none'><hr>We prove new results on the polarizing random walk framework introduced in recent works of Chattopadhyay et al. [CHHL18, CHLT19] that exploit $L_1$ Fourier tail bounds for classes of Boolean functions to construct pseudorandom generators (PRGs).  We show that given a bound on the $k$-th level of the Fourier spectrum, one can construct a PRG with a seed length whose quality scales with $k$.  This interpolates previous works, which either require Fourier bounds on all levels [CHHL18], or has polynomial dependence on the error parameter in the seed length [CHLT19], and thus answers an open question in [CHLT19].  As an example, we show that for polynomial error, Fourier bounds on the first $O(\log n)$ levels is sufficient to recover the seed length in [CHHL], which requires bounds on the entire tail.

  We obtain our results by an alternate analysis of fractional PRGs using Taylor's theorem and bounding the degree-$k$ Lagrange remainder term using multilinearity and random restrictions.  Interestingly, our analysis relies only on the <i>level-k unsigned Fourier sum</i>, which is  potentially a much smaller quantity than the $L_1$ notion in previous works.  By generalizing a connection established in [CHHLZ20], we give a new reduction from constructing PRGs to proving correlation bounds.

  Finally, using these improvements we show how to obtain a PRG for $\mathbb{F}_2$ polynomials with seed length close to the state-of-the-art construction due to Viola [Vio08].<hr></div></LI>

  <LI> <b> Virtues of Patience in Strategic Queuing Systems, </b> with &Eacuteva Tardos. <br> <i>The Twenty-Second ACM Conference on Economics and Computation (EC 21). </i> <br>[<a onclick='$("#abstract_div_gt21").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/pdf/2011.10205.pdf' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=-OvqfSPosRQ' target='_blank'>EC Talk</a>]<br><div id='abstract_div_gt21' style='display:none'><hr>We consider the problem of selfish agents in discrete-time queuing systems, where competitive queues try to get their packets served. In this model, a queue gets to send a packet each step to one of the servers, which will attempt to serve the oldest arriving packet, and unprocessed packets are returned to each queue. We model this as a repeated game where queues compete for the capacity of the servers, but where the state of the game evolves as the length of each queue varies, resulting in a highly dependent random process. In classical work for learning in repeated games, the learners evaluate the outcome of their strategy in each step---in our context, this means that queues estimate their success probability at each server. Earlier work by the authors [in EC'20]
  shows that with no-regret learners the system needs twice the capacity as would be required in the coordinated setting to ensure queue lengths remain stable, despite the selfish behavior of the queues. In this paper, we demonstrate that this myopic way of evaluating outcomes is suboptimal: if more patient queues choose strategies that selfishly maximize their <i>long-run success rate</i>, stability can be ensured with just $\frac{e}{e-1}\approx 1.58$ times extra capacity, strictly better than what is possible assuming the no-regret property.


   As these systems induce highly dependent random processes, our analysis draws heavily on techniques from the theory of stochastic processes to establish various game-theoretic properties of these systems. Though these systems are random even under any
   fixed stationary policies by the queues, we show using careful probabilistic arguments that surprisingly, under such fixed policies, these systems have essentially deterministic and explicit asymptotic behavior. We show that the growth rate of a set can be written as the ratio of a submodular and modular function, and
   use the resulting explicit description to show that the subsets of queues with largest growth rate is closed under union and non-disjoint intersections, which we use in turn to prove the claimed sharp bicriteria result for the equilibria of the resulting system. Our equilibrium analysis relies on a novel deformation argument towards a more analyzable
   solution that is quite different from classical price of anarchy bounds. While the intermediate points in this deformation will <i>not</i> be Nash, the structure will ensure the relevant constraints and incentives similarly hold to establish monotonicity along this continuous path.<hr></div></LI>

   <LI> <b> Polarization in Geometric Opinion Dynamics, </b> with Jon Kleinberg and &Eacuteva Tardos. <br> <i>The Twenty-Second ACM Conference on Economics and Computation (EC 21). </i> <br>[<a onclick='$("#abstract_div_gkt21").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/pdf/2106.12459.pdf' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=W7g3yvMrels' target='_blank'>EC Talk</a>]<br><div id='abstract_div_gkt21' style='display:none'><hr>In light of increasing recent attention to political polarization, understanding how polarization can arise poses an important theoretical question. While more classical models of opinion dynamics seem poorly equipped to study this phenomenon, a recent novel approach by H&#7567z<strike>l</strike>a, Jin, Mossel, and Ramnarayan [HJMR20] proposes a simple geometric model of opinion evolution that provably exhibits strong polarization in specialized cases. Moreover, polarization arises quite organically in their model: in each time step, each agent updates opinions according to their correlation/response with an issue drawn at random. However, their techniques do not seem to extend beyond a set of special cases they identify, which benefit from fragile symmetry or contractiveness assumptions, leaving open how general this phenomenon really is.

  In this paper, we further the study of polarization in related geometric models. We show that the exact form of polarization in such models is quite nuanced: even when strong polarization does not hold, it is possible for weaker notions of polarization to nonetheless attain. We provide a concrete example where weak polarization holds, but strong polarization provably fails. However, we  show that strong polarization  provably holds in many
variants of the HJMR model, which are also robust to a wider array of distributions of random issues---this suggests that the form of polarization introduced by HJMR is more universal than suggested by their special cases. We also show that the
weaker notions connect more readily to the theory of Markov chains on general state spaces.


  <LI><b>Stability and Learning in Strategic Queuing Systems,</b> with &Eacuteva Tardos. <br> <i> The Twenty-First ACM Conference on Economics and Computation (EC 20)</i>.<br>[<a onclick='$("#abstract_div_gt20").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/pdf/2003.07009.pdf' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=sDBARYfc4-o' target='_blank'>EC Talk</a>]<br><div id='abstract_div_gt20' style='display:none'><hr>Bounding the price of anarchy, which quantifies the damage to social welfare due to selfish behavior of the participants, has been an important area of research. In this paper, we study this phenomenon in the context of a game modeling queuing systems: routers compete for servers, where packets that do not get service will be resent at future rounds, resulting in a system where the number of packets at each round depends on the success of the routers in the previous rounds. We model this as an (infinitely) repeated game, where the system holds a state (number of packets held by each queue) that arises from the results of the previous round. We assume that routers satisfy the no-regret condition, e.g. they use learning strategies to identify the server where their packets get the best service.
Classical work on repeated games makes the strong assumption that the subsequent rounds of the repeated games are independent (beyond the influence on learning from past history). The carryover effect caused by packets remaining in this system makes learning in our context result in a highly dependent random process. We analyze this random process and find that if the capacity of the servers is high enough to allow a centralized and knowledgeable scheduler to get all packets served even with double the packet arrival rate, and queues use no-regret learning algorithms, then the expected number of packets in the queues will remain bounded throughout time, assuming older packets have priority. This paper is the first to study the effect of selfish learning in a queuing system, where the learners compete for resources, but rounds are not all independent: the number of packets to be routed at each round depends on the success of the routers in the previous rounds.<hr></div></LI>

<LI><b>Adversarial Perturbations of Opinion Dynamics in Networks,</b> with Jon Kleinberg and &Eacuteva Tardos. <br> <i>The Twenty-First ACM Conference on Economics and Computation (EC 20)</i>.<br>[<a onclick='$("#abstract_div_gkt20").toggle()'><font color = "#0000ff">Abstract</font></a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://arxiv.org/pdf/2003.07010.pdf' target='_blank'>PDF</a>]&nbsp&nbsp&nbsp&nbsp[<a href='https://www.youtube.com/watch?v=VoLBfqQB3wE' target='_blank'>EC Talk</a>]<br><div id='abstract_div_gkt20' style='display:none'><hr>We study the connections between network structure, opinion dynamics, and an adversary's power to artificially induce disagreements. We approach these questions by extending models of opinion formation in the social sciences to represent scenarios, familiar from recent events, in which external actors seek to destabilize communities through sophisticated information warfare tactics via fake news and bots. In many instances, the intrinsic goals of these efforts are not necessarily to shift the overall sentiment of the network, but rather to induce discord. These perturbations diffuse via opinion dynamics on the underlying network, through mechanisms that have been analyzed and abstracted through work in computer science and the social sciences. We investigate the properties of such attacks, considering optimal strategies both for the adversary seeking to create disagreement and for the entities tasked with defending the network from attack. We show that for different formulations of these types of objectives, different regimes of the spectral structure of the network will limit the adversary's capacity to sow discord; this enables us to qualitatively describe which networks are most vulnerable against these perturbations. We then consider the algorithmic task of a network defender to mitigate these sorts of adversarial attacks by insulating nodes heterogeneously; we show that, by considering the geometry of this problem, this optimization task can be efficiently solved via convex programming. Finally, we generalize these results to allow for two network structures, where the opinion dynamics process and the measurement of disagreement become uncoupled, and determine how the adversary's power changes; for instance, this may arise when opinion dynamics are controlled an online community via social media, while disagreement is measured along "real-world" connections.<hr></div></LI>


</OL>
<hr>
<font size="6">Teaching</font>

<ul>
              <li> Spring 2023: <a href="https://www.cs.cornell.edu/courses/cs6850/2023sp/">CS 6850 The Structure of Information Networks</a>. Cornell University. Teaching Assistant.</li>
              <li> Fall 2022: <a href="https://www.cs.cornell.edu/courses/cs6820/2022fa/">CS 6820 Graduate Algorithms</a>. Cornell University. Teaching Assistant.</li>
               <li> Spring 2018: <a href="https://math.dartmouth.edu/~auel/courses/370s18/">MATH 370 Fields and Galois Theory</a>. Yale University. Teaching Assistant.</li>
               <li> Fall 2017: <a href="https://math.dartmouth.edu/~auel/courses/350f17/">MATH 350 Introduction to Abstract Algebra</a>. Yale University. Teaching Assistant.</li>
            </ul>



<hr>
</body>


</html>
